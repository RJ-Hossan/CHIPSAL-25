{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi3YnPQ-MdKT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('/kaggle/input/chipsal-task3/SubTask-C-train.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/chipsal-task3/SubTask-C-(indextweet)test.csv')"
      ],
      "metadata": {
        "id": "q1zE56vFMfjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Different BERT Models\n",
        "\n",
        "\n",
        "Run only the bert you want and configure as per requirements."
      ],
      "metadata": {
        "id": "gdQ2hVReMuie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model and tokenizer for MuRIL Large\n",
        "model_name = \"google/muril-large-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n"
      ],
      "metadata": {
        "id": "d3i-eQyoMnJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model and tokenizer for Verta BERT\n",
        "model_name = \"rahular/varta-bert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "id": "dsUnMVweMtFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model and tokenizer for XLM-RoBERTa Large\n",
        "model_name = \"xlm-roberta-large\"\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "id": "tqKXi-PHOaFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "id": "E2O3ajrmOk8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the data\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['tweet'], padding=True, truncation=True, max_length=128)\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_data['tweet'].tolist(), train_data['label'].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_data['tweet'].tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "class DevanagariDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = DevanagariDataset(train_encodings, train_labels)\n",
        "val_dataset = DevanagariDataset(val_encodings, val_labels)\n",
        "test_dataset = DevanagariDataset(test_encodings)\n"
      ],
      "metadata": {
        "id": "CdzcOZX2ONRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision = precision_score(labels, preds, average='weighted')\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "zUHuirS5NiUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Helper function to ensure tensors are contiguous\n",
        "def make_model_contiguous(model):\n",
        "    for param in model.parameters():\n",
        "        if not param.is_contiguous():\n",
        "            param.data = param.data.contiguous()\n",
        "    return model"
      ],
      "metadata": {
        "id": "JrNm2eDnNq6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Arguments with Early Stopping\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results_muril_large',\n",
        "    num_train_epochs=13,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_total_limit=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    warmup_steps=400,\n",
        "    weight_decay=0.06,\n",
        "    gradient_accumulation_steps=8,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "\n",
        "    greater_is_better=True,\n",
        "    fp16=False,  # Disable mixed precision\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "5HmcgCvHNzdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "DdJw10iaN458"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make model contiguous and save\n",
        "model = make_model_contiguous(model)\n",
        "trainer.save_model('./best_model_muril_large')"
      ],
      "metadata": {
        "id": "C2aYNDlcN_mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "predictions = trainer.predict(test_dataset)\n",
        "pred_labels = predictions.predictions.argmax(-1)"
      ],
      "metadata": {
        "id": "yr7qb9ZuOCOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions\n",
        "with open(\"predictions_muril_large.json\", \"w\") as f:\n",
        "    for idx, label in zip(test_data['index'], pred_labels):\n",
        "        json.dump({\"index\": int(idx), \"prediction\": int(label)}, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"Predictions saved to predictions.json\")\n"
      ],
      "metadata": {
        "id": "Ve5Kq44HOEqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers\n"
      ],
      "metadata": {
        "id": "0DgVf73ZMgaR"
      }
    }
  ]
}